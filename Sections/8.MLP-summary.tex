MultiLayer Perceptrons(MLP) are a type of supervised learning \cite{michie1994machine}. It is a type of neural network, invented in 1969 \cite{minsky1969perceptions}, which at the time  was inspired by the way the human brain functions. A MLP consists of an input layer, hidden layers and an output layer. To have a better understanding of how this works, let's first look at a (single layer) perceptron\cite{rosenblatt1958perceptron}. 

A perceptron \ref{fig:perceptron} is a system of nodes with input nodes, called the input layer, and an output node called the output layer. It functions very much like neurons in the brain. Inputs from a vector $x$ are fed to the input layer with weights $w$. The dot product of $x$ and $w$, $\sum$ ,  is fed to an activation function. The output again resembles that of a neuron, in the sense that it "fires" if the activation function passes the threshold value. This threshold value corresponds to, what in classification, is known as a decision boundary. It represents the difference between classes. However, perceptrons cannot solve all problems. To be specific, non separable problems cause problems. MLP can handle problems that are more complex. \\
\begin{figure}[H]
    \includegraphics[width=80mm]{./img/perceptron.png}
    \caption{\footnotesize{Rosenblatt's Perceptron \cite{wikiPerceptronPNG}}}
    \label{fig:perceptron}
\end{figure}

A MLP works in a similar way, but just repeated many times. The input layer consists of neurons. Neurons in this sense are very much like perceptrons, but they can use different kinds of activation functions. Each neuron passes its output to the hidden layer. In the hidden layer, a number of neurons take these outputs as input and pass their output to the output layer of the MLP. This concept of only passing outputs forward in the network is called "feed forward". Often only one hidden layer is used since this can already approximate most continues functions \cite{cybenko1989approximation}. However, non-linear activation functions are also possible. 

Learning in the human brain is done by strengthening the connection between neurons. This is mimicked in MLP by adjusting the weights in the neurons. Something with a desired result will have its weight increased so certain inputs contribute more to the activation function than others. This is possible because we employ supervised learning. Whether or not a weight should be increased, and by how much, is done through error calculation with backpropagation. Backpropagation is another term for Backwards Propagation or Errors \cite{rumelhart1985learning} and is also sometimes referred to as the Generalized Delta Rule. Backpropagation works by going back through the network (output to input) and calculating how much each node contributed to the observed error using a loss function. There are many ways to calculate these contributions to the observed error, but a common example is the mean squared error. Once a certain error is established we can correct the weights $w$. To do this we need the gradient $\sigma$ function which is the derivative of the activation function times the difference between desired value and actual output of our node. To make sure we do not converge too rapidly or slowly towards the optimal value for our weights, we use $\alpha$ and $l$ as multipliers. We will define $y$ as the output of previous node (where the weight/edge starts). For any training cycle or "epoch" $n$ the learning function as stated by Hinton et al. is $w(n+1)=w(n) + \alpha * w(n-1) + \sigma * l * y$. Typically, $\alpha$ is very small (e.g. $0.0001$) and $l$ is slightly bigger (e.g. $0.25$). By repeating the process of backpropagation, we keep adjusting our weights until our error becomes or gets close to zero.

Performance of a MLP largely depends on two things. Firstly, the number of nodes and number of hidden layers. More layer and nodes increases accuracy after proper training. However, this also increases the risk of over fitting. Too few nodes is also undesirable because this leads to a too generalized classification, which results in low accuracy \cite{Murtagh1991183}. 
The second aspect of reaching high performance is the training duration. If the training duration is too short, it will not have learned enough. This leads to low accuracy. Training too long leads to over fitting \cite{caruana2001overfitting}. 

The MLP does not have the easiest structure. In some cases this complexity pays off with higher accuracy. As mentioned before, it can deal with non-linear functions \cite{gardner1998artificial}. Because of the non-linear functions, MLP can achieve high accuracy when classifying datasets. But if the structure of the network is not optimal, the efficiency drops. Too many nodes or layers increase computation time significantly.