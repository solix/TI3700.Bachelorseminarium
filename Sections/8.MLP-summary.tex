MultiLayer Perceptrons(MLP) are a type of supervised learning \cite{michie1994machine}. It is a type of neural network, invented in 1969 \cite{minsky1969perceptions}, which at the time  was inspired by the way the human brain functions. A MLP consists of an input layer, hidden layers and an output layer. To have a better understanding of how this works, let's first look at a (single layer) perceptron\cite{rosenblatt1958perceptron}. 

A perceptron \ref{fig:perceptron} is a system of nodes with input nodes, called the input layer, and an output node called the output layer. It functions very much like neurons in the brain. Inputs from a vector $x$ are fed to the input layer with weights $w$. The dot product of $x$ and $w$, $\sum$ ,  is fed to an activation function. The output again resembles that of a neuron, in the sense that it "fires" if the activation function passes the threshold value. This threshold value corresponds to, what in classification, is known as a decision boundary. It represents the difference between classes. However, perceptrons cannot solve all problems. To be specific, non separable problems cause problems. MLP can handle problems that are more complex. \\
\begin{figure}[H]
    \includegraphics[width=80mm]{./img/perceptron.png}
    \caption{\footnotesize{Rosenblatt's Perceptron \cite{wikiPerceptronPNG}}}
    \label{fig:perceptron}
\end{figure}

A MLP works in a similar way, but just repeated many times. The input layer consists of perceptrons. Each perceptron passes its output to the hidden layer. In the hidden layer, a number of perceptrons take these outputs as input and pass their output to the output layer of the MLP. This concept of only passing outputs forward in the network is called "feed forward". Often only one hidden layer is used since this can already approximate most continues functions \cite{cybenko1989approximation}. However, non-linear activation functions are also possible. Increasing the number of hidden layers or nodes in layers increases sensitivity but also increases risk of overfitting \cite{Murtagh1991183}.

Learning in the human brain is done by strengthening the connection between neurons. This is mimicked by adjusting the weights in the perceptrons. Something with a desired result will have its weight increased so certain inputs contribute more to the activation function than others. This is possible because we employ supervised learning. Whether or not a weight should be increased, and by how much, is done through error calculation with backpropagation. Backpropagation is another term for Backwards Propagation or Errors \cite{rumelhart1985learning} and is also sometimes referred to as the Generalized Delta Rule. Backpropagation works by going back through the network (output to input) and, at every node, calculating the error, using the loss function. There are many ways to calculate the error, but a common example is the mean squared error. Once a certain error is established we can correct the weights $w$. To do this we need the gradient $\sigma$ function which is the derivative of the activation function times the difference between desired value and actual output of our node. To make sure we don't go to fast or to slow when converging our weights to an optimal value, we use $\alpha$ and $l$ as multipliers. We will define $y$ as the output of previous node (where the weight/edge starts). For any training cycle or "epoch" $n$ the learning function as stated by Hinton et al. is $w(n+1)=w(n) + \alpha * w(n-1) + \sigma * l * y$. Typically, $\alpha$ is very small (e.g. $0.0001$) and $l$ is slightly bigger (e.g. $0.25$). By repeating the process of backpropagation, we keep adjusting our weights until our error becomes or gets close to zero.

The MLP has a couple of strong advantages. Firstly, MLP does not make assumptions on the distribution of a dataset. This makes for great generalization and allows MLP to handle new datasets extremely well. As mentioned before, it can also deal with non-linear functions \cite{gardner1998artificial}. Because of the non-linear functions, MLP can achieve high accuracy when classifying datasets. This all leads to some very clear advantages over other classifiers. But if the structure of the network is not optimal, the efficiency drops. Too many nodes or layers increase computation time significantly.