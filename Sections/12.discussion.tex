There are some key issues for effectively classifying dark spots, several factors should be taken into account \cite{Kubat:1998:MLD:288808.288812}. First of all, the available data containing oil spills is scarce compared to lookalikes. This leads to a very imbalanced dataset. As a consequence, a classifier sensitive to this problem can not reach it's maximum accuracy \cite{Japkowicz20026}. SVM seem the least affected by this imbalance. Second, there is no guarantee that the data used for training the classifier are representatives of future samples, especially with such a scarce dataset as in oil spill detection. This issue is known as the validity of data. Furthermore, the feature selection procedure should be done with care as it can influence prediction accuracy. Out of the 25 common features, most researchers arbitrarily select a subset of features and compare multiple subsets using cross-validation, a technique for estimating how well a model generalizes to an independent dataset. Finally, a classifier should be chosen with all the issues mention in mind including ease of interpretation and training times in a highly dynamic environment. In the table \ref{fig:table}, all previously mentioned studies are shown including their results and characteristics. This should allow a better discussion on which classifier is well suited for oil spill detection.

\begin{table*}[t]

\advance\leftskip-3cm
\setstretch{1.5}
\tabcolsep=0.19cm
\small
\centering


%\adjustbox{max width=0.97\pdfpagewidth, left}{
\begin{adjustbox}{width=\textwidth,totalheight=\textheight,keepaspectratio}
\begin{tabular}{*{6}{|l|}}

\toprule[1.5pt]
  \textbf{Study} & \textbf{Data Type} & \textbf{Preprocessing} & \# \textbf{Features} & \textbf{Formations(lookalike \& oilspills)} & \textbf{Results} \\
    \hline
  
    Hydro-acoustics \cite{Robotham2011170} & Sonar & Echoview & 15 &  - & SVM accuracy: $89.5$\%, DT accuracy: $86.8$\% \\

    Land coverage1986 \cite{Otukei2010S27} & LandSat SAR & `Using data miner' & 11 &  - & SVM max accuracy: $90.53$\%, DT accuracy: $93.48$\% \\

    Land coverage2001 \cite{Otukei2010S27} & LandSat SAR & `Using data miner' & 10 &  - & SVM max accuracy: $93.67$\%, DT accuracy: $94.07$\% \\ 
    
    Oil spills\cite{Topouzelis200762} & ERS-2 SAR, 24 high-res images 8-bit & transformation, Filtering, data normalization & 10 & 90  \& 69  & MLP(10:51:2) accuracy: $86.67$\% lookalike acc. $91.18$\% oil spills acc.\\
    
    Oil spills\cite{Delfrate200038} & ERS SAR, 600 low-res images & Resampling,Radiometric range correction, georeference & 11 & 68  \& 71  & MLP(11-8-4-1) accuracy: $90$\% lookalike acc. $82$\% oil spills acc.\\
    
    Oil spills\cite{Topouzelis200930} &  ERS-2 SAR, 24 high-res images & - & 10 & 90 \& 69  & MLP(10-51-2) accuracy: $84.4$\% lookalike acc. $85.3$\% oil spills acc.\\
    
    Oil spills\cite{Topouzelis200924} &  ERS SAR, 12 high-res images & 8-bit transformation, filtering & - & - & MLP(4-2-1) accuracy: $96.46$\% overall acc. \\
 
    Oil spills\cite{Delfrate2004} &  ERS SAR, 70 images & - & 12 & 78 \& 111  & MLP(12-8-8-1) 0.227 root mean square error(rmse)\\
    
    Oil spills\cite{Xu201414} &  RADARSAT-1, 93 images & log-transformation, standardization & 15 & 94  \& 98  & MLP $75.93$\% overall acc. SVM $79.63$\% overall acc. DT(Bundling) 90.74 overall acc.\\
    
    Oil spills\cite{Mera201472} &  Envisat, 47 images & - & 9 & 155  \& 80  & MLP(9:11:2) $96.3$\% lookalike acc. $92.9$\% oil spill acc. \\
    & & & & & DT $92.6$\% lookalike acc. $92.9$\% oil spill acc. \\
    
    Oil spills\cite{Delfrate1996} &  ERS-1 SAR, 59 low-res images & - & 9 & 2471 \& 42  & DT $96$\% lookalike acc. $86$\% oil spill acc\\
    
    Oil spills\cite{Topouzelis201268} &  ERS-2 SAR, 24 high-res images & - & 9 & 90  \& 69  & DT forest $84.4$\%\\ 
    
    Oil spills\cite{brekke2008classifiers} & ENVISAT, 103 images & masking & - & 12244 \& 41  & SVM(C-SVC) $77.4$\% lookalike acc. $82.9$\% oil spill acc.\\

    ECG arrhythmias\cite{Moavenian20103088} & MIT-BIH arrhythmia database & - & 10 & - & accuracy SVM 99\% , MLP 98.22\% \\

    Remote Sensing\cite{Zanaty2012177} & Satimage & feature extraction & 26& - & accuracy for SVM 93.16\% ,and for MLP 96.98\%\\
    
    signature recognition\cite{FriasMartinez2006693} & user signature data &feature extraction& 2 & - & Recognition rate SVM 66.5  , MLP 71.2\\
    wind speed prediction\cite{Mohandes2004939}& daily wind speed data & - &high dimensional feature & - & MSE on testing data for the MLP is 0.0090 while it is 0.0078 for the SVM\\
    
    Hashimoto's disease\cite{Omiotek201340} &  66 Thyroid ultrasound images & normalization & 59 & 54 healthy and 85 sick & MLP(6-8-1): $89.4$\% sick class $61.1$\% healthy class. DT: $89.4$\% sick class $94.4$\% healthy class. \\
    
    \bottomrule[1.5pt]
    
\end{tabular}
\end{adjustbox}
\caption{\footnotesize{An Overview of oil spill and related studies with their results and charateristics}}
\label{fig:table}
\end{table*}

These studies reported varying results in accuracy. Studies not related to oil spills have shown similar performance. Accuracies up to 96\% are claimed\cite{Topouzelis200924}, but without even specifying the data used for training and testing, these results are highly questionable. When looking at the table\ref{fig:table}, it is hard and inappropriate to directly compare classifiers in terms of accuracy since they all use a different dataset. Researchers have tried to eliminate this issue by using the same dataset for each of the classifiers in a comparison\cite{Mera201472}\cite{Xu201414}. Even though classifiers are trained with the same data, the validity of data issue persists. Since real world samples are scarcely available, classifiers may be insufficiently trained to generalize the dataset. Much improvement in classifier comparisons can be achieved if researchers would have access to a common database\cite{Topouzelis200810}.
An emphasis exists on the minimization of false negatives for detecting oil spills. In an automatic decision support system where many images are analyzed, an oil spill classified as a lookalike will have higher environmental consequences. Another factor that has an impact on accuracy are the selected features used as input to a classifier. Although in most cases a similar amount of features is used, only some are taken together in different studies. The search for an optimal set of features has been tried using a genetic algorithm \cite{Topouzelis200930}, but this may not exist.
MLP is often used in oil spill detection and increasingly in the more broad remote sensing as well. Their ability to simultaneously handle non-linear data of a multi-dimensional input space is a large advantage. Furthermore, they do not require an explicit well defined relationship between input and output as they determine the relationship on their own using training set data. This ability to learn is why MLP are considered reliable classifiers and useful for oil spill detection \cite{Delfrate200038}. Surprisingly, decision trees achieve a similar performance compared to the more complex SVM and MLP. This can be attributed to the fact that decision trees perform better when dealing with categorical features and that SVM and MLP require a large dataset to achieve its maximum prediction accuracy \cite{kotsiantis2007supervised}. Apart from this, decision trees are easily understood. This intuitiveness is important because classification systems in oil spill detection usually serve as a decision support system. Decision trees are faster to train, but the classifiers are only trained once. When a large dataset is available, MLP and SVM are well suited for detecting oil spills, because they both perform well when a non-linear relationship exist between the input and output features \cite{kotsiantis2007supervised}. If training data is scarce however then decision trees can be considered since SVM and MLP are more prone to overfitting in oil spill detection\cite{Xu201414}.
