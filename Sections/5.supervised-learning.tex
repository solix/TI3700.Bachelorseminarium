Machine learning corresponds to the study and construction of systems that can learn from data. These systems can be useful when typical rule based programs that follow explicit instructions do not give good performance. Their ability to learn makes them popular in the field of artificial intelligence and pattern recognition. Machine learning can take several forms. In this paper, we look specifically at classifiers within the field of supervised learning. In supervised learning the system is trained or `taught' using input data that is known to belong to a certain class.\\ 
%A mapping between the inputs and outputs is inferred from the training data which can be used to classify unseen data. \cite{cord2008machine}

For the purpose of understanding how supervised learning works, consider a supervised learning model that is shown in fig \ref{fig:SL}. The first step is to normalize raw data and prepare data for the training set and validation set. Next data is randomly allocated to these two sets (usually $60$\% for the training set and the rest for validation set). The training set is used by classifier to learn how to classify the data. The training data will be fed to the algorithm in order to learn from training data so that it can train or build a model that can predict unseen data. When the model is built, it is validated using the validation set. It is important in this stage to use data that are not used by the model before, which is why in the second step of figure \ref{fig:SL} the data is split into two. If the validation results in an error rate larger than the desired error, the model is tweaked and we adjust the parameters. Since the built model has already seen the training data, and has memorized the answer, is not trustworthy anymore. If we continue training on that data, the model will try to memorize the classes of the data points specifically instead of learning to classify a type of data. This will make generalization property of the model become progressively worse and is known as over fitting or over training \cite{hawkins2004problem} problem in machine learning. However, depending on the type of a classifier, there are techniques to avoid over fitting. For example a method \cite{Piotrowski201397} has been proposed to solve over fitting in neural network training. Once a model shows consistency, it can be used to predict and label unknown data. \\  
 
\begin{figure}[H]
\centering
    \includegraphics[width=38mm,scale=0.3]{./img/SL.png}
    \caption{\footnotesize{An overview of Supervised learning model that divides scaled data into two sets in order to build a model and predict unseen data }}
    \label{fig:SL}
\end{figure}

%In unsupervised learning, no associated label, which is the desired output for a set of inputs, is given to the learning algorithm. The class belonging to each instance in the dataset is unknown and there is no reward when the classifier picks the right class. This technique is therefore more often used when trying to discover hidden classes in new datasets \cite{maglogiannis2007emerging}.






