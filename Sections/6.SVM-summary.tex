A Support Vector Machine(SVM) is a classifier which looks for an optimal hyperplane or set of hyperplanes in high-dimensional space to classify new data. A hyperplane in a n-dimensional space, is a subspace of one dimension less than the whole space. In figure \ref{fig:SVM} a hyperplane in 2-dimensional space is a line which divides the 2-dimensional space in half. This division defines a closed half-space and an open half-space, and represents the division between two classes. The original idea for SVM was conceived by Cortes and Vapnik in 1995 \cite{cortes1995support} \\
In figure \ref{fig:SVM}, the main idea behind SVM is shown. Consider for example a dataset described by variables $x_1$ and $x_2$ and suppose we want to classify all the elements(elements are shown by class circle and class square), then the operation of an SVM algorithm is based on finding the optimal hyperplane between the two classes \cite{opencv_library}. An optimal hyperplane is one that gives the largest minimum distance to the classes and it maximizes the margin between the hyperplane and all data points. %i.e. the best line that leaves the maximum margin from both classes.

\begin{figure}[H]
    \includegraphics[width=0.45\textwidth]{./img/SVM.png}
    \caption{\footnotesize{SVM with a Maximum-margin hyperplane and margins trained with samples from two classes, circle and square. Samples on the margin are called the support vectors.\cite{wiki:SVM}}}
    \label{fig:SVM}
\end{figure}

SVM classifier can be explained more intuitively by giving an example with real world data. Suppose in figure \ref{fig:SVM} a set of objects is given that are extracted from an image taken in a park. Here the goal is to classify the objects into two classes using the SVM classifier; To draw a line such that Tree objects (circle class) be separated from other  green plants objects (square class). We employ two geometrical features, height of the object ($x_2$) and thickness of the stem ($x_1$) as arguments for classification. If we run the SVM model, we see the hyperplane shown in figure \ref{fig:SVM} correctly separates the two classes due to the fact that the tree has more height than other green plants and its trunk is thicker than plant stem.\\  

SVM is popular for numerous theoretical reasons: SVM classifiers are robust against the curse of dimensionality and over fitting. This is because it computes dot products in function, which is relatively low in cost. They also need less memory to store the predictive model, because a hyperplane requires little space. \\
%Even when training samples have some bias, when the right parameters are chosen, SVM  remains be robust \cite{auria2008support} and can learn both simple and complex classification models \cite{cristianini2000}. 

SVMs are the best known member in the general category of kernel methods. Kernel methods are a class of algorithms often used in pattern analysis, which can operate on general types of data (e.g. Strings, vector, text) and looks for general relations between data points (ranking, classification, clusters). Kernel method depends only on the data in the form of dot products. Afterwards, these dots products can be replaced with a kernel function. The core task of the kernel is to compute a dot product in a new vector space. Therefore kernel makes it feasible to apply the original SVM algorithm in this new vector space. \\  


%In the first step, data points are processed in a vector space(kernel matrix) through a mapping function(kernel function). Second, different kernel algorithms can be used in order to analyze the data, using only the information that resides in the kernel matrix. \cite{shawe2004kernel}\\

%This allows the user to apply a classifier to data that has infinite- dimensional vector space representation such as DNA or protein \cite{ben2010user}. \\




In recent years, SVMs have been widely used in bio-informatics \cite{furey2000support,osuna1997training,guyon2002gene} and other disciplines due to its ability to accurately deal with high dimensional data\cite{joachims1998text}. In marine environments, researchers have proposed a method for detection of oil spills in SAR images, using SVM as a classifier. A study has shown that SVM has better performance on SAR images when using a texture analysis and decomposition algorithm in various steps of the SVM algorithm. Texture analysis will help to reduce noise in SAR images \cite{matkan2013oil}.

